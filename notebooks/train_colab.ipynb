{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JEPA Reasoner — A100 Training on Colab\n",
    "\n",
    "Full training pipeline for the I-JEPA cross-domain latent reasoning system.\n",
    "\n",
    "**Before running:** Go to `Runtime → Change runtime type → A100 GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone repo and install dependencies\n",
    "!git clone https://github.com/akshai0296/jepa_reasoner.git\n",
    "%cd jepa_reasoner\n",
    "!pip install -q torch transformers sentence-transformers datasets tokenizers scikit-learn tqdm wandb openai anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Verify GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Go to Runtime → Change runtime type → A100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. (Optional) Set API keys for LLM feedback loop\n",
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"       # for self-improvement loop\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\" # alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load data\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from src.utils.data_loading import load_gsm8k, load_math_dataset, generate_synthetic_math\n",
    "\n",
    "print(\"Loading GSM8K...\")\n",
    "gsm8k_data = load_gsm8k(\"train\", max_samples=7000)\n",
    "print(f\"  GSM8K: {len(gsm8k_data)} examples\")\n",
    "\n",
    "print(\"Loading MATH competition dataset...\")\n",
    "math_data = load_math_dataset(\"train\", max_samples=5000)\n",
    "print(f\"  MATH: {len(math_data)} examples\")\n",
    "\n",
    "print(\"Generating synthetic arithmetic...\")\n",
    "synth_data = generate_synthetic_math(3000)\n",
    "print(f\"  Synthetic: {len(synth_data)} examples\")\n",
    "\n",
    "import random\n",
    "all_data = gsm8k_data + math_data + synth_data\n",
    "random.shuffle(all_data)\n",
    "split = int(len(all_data) * 0.9)\n",
    "train_data = all_data[:split]\n",
    "val_data = all_data[split:]\n",
    "print(f\"\\nTotal: {len(train_data)} train, {len(val_data)} val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build model (full-size for A100)\n",
    "from src.models import JEPAReasoner\n",
    "\n",
    "model = JEPAReasoner(\n",
    "    domain=\"math\",\n",
    "    latent_dim=768,\n",
    "    predictor_type=\"transformer\",\n",
    "    predictor_kwargs={\n",
    "        \"hidden_dim\": 1024,\n",
    "        \"num_layers\": 6,\n",
    "        \"num_heads\": 8,\n",
    "        \"dropout\": 0.1,\n",
    "        \"use_latent_z\": False,\n",
    "        \"num_predictor_tokens\": 8,\n",
    "    },\n",
    "    decoder_type=\"scratch\",\n",
    "    decoder_kwargs={\n",
    "        \"hidden_dim\": 768,\n",
    "        \"num_layers\": 6,\n",
    "        \"num_heads\": 8,\n",
    "        \"max_seq_len\": 512,\n",
    "        \"num_latent_tokens\": 8,\n",
    "        \"latent_dim\": 768,\n",
    "    },\n",
    "    freeze_backbone=False,\n",
    "    ema_decay=0.996,\n",
    ")\n",
    "\n",
    "total = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "print(f\"Total params: {total:.1f}M | Trainable: {trainable:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train — Full 3-stage pipeline\n",
    "from src.train import Trainer\n",
    "\n",
    "config = {\n",
    "    \"domains\": [\"math\"],\n",
    "    \"latent_dim\": 768,\n",
    "    \"device\": \"cuda\",\n",
    "\n",
    "    # Stage 1: Predictor\n",
    "    \"predictor_epochs\": 40,\n",
    "    \"lr_predictor\": 1e-4,\n",
    "\n",
    "    # Stage 2: Decoder\n",
    "    \"decoder_epochs\": 25,\n",
    "    \"lr_decoder\": 5e-5,\n",
    "\n",
    "    # Stage 3: Joint\n",
    "    \"finetune_epochs\": 15,\n",
    "    \"lr\": 3e-5,\n",
    "\n",
    "    # Training\n",
    "    \"batch_size\": 32,\n",
    "    \"max_context_len\": 256,\n",
    "    \"max_target_len\": 256,\n",
    "    \"use_amp\": True,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"weight_decay\": 0.01,\n",
    "\n",
    "    # Loss\n",
    "    \"loss_type\": \"l2\",\n",
    "    \"contrastive_weight\": 0.1,\n",
    "\n",
    "    \"freeze_backbone\": False,\n",
    "    \"output_dir\": \"checkpoints/a100_full\",\n",
    "}\n",
    "\n",
    "trainer = Trainer(model, train_data, val_data, config)\n",
    "results = trainer.run_full_pipeline()\n",
    "print(f\"\\nFinal metrics: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Test on math problems\n",
    "import torch.nn.functional as F\n",
    "from src.utils.metrics import latent_space_stats, cosine_similarity_score\n",
    "\n",
    "model.eval()\n",
    "tokenizer = model.context_encoder.tokenizer\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "test_problems = [\n",
    "    \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells every duck egg at the farmers' market daily for $2. How much in dollars does she make every day at the farmers' market?\",\n",
    "    \"What is 15 + 27?\",\n",
    "    \"A store has 45 apples. If 18 are sold, how many remain?\",\n",
    "    \"Calculate: 12 * 5 + 3\",\n",
    "    \"If a train travels at 60 mph for 2.5 hours, how far does it go?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  INFERENCE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_s_y = []\n",
    "for problem in test_problems:\n",
    "    enc = tokenizer(problem, return_tensors=\"pt\", padding=\"max_length\", max_length=256, truncation=True)\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s_x = model.encode_context(enc[\"input_ids\"], enc[\"attention_mask\"])\n",
    "        s_y_hat = model.predict(s_x)\n",
    "        decoded = model.decoder.generate(s_y_hat, max_new_tokens=128, temperature=0.5)\n",
    "        all_s_y.append(s_y_hat.cpu())\n",
    "\n",
    "    print(f\"\\n  Q: {problem[:80]}{'...' if len(problem)>80 else ''}\")\n",
    "    print(f\"  A: {decoded[0][:200]}\")\n",
    "\n",
    "# Latent health\n",
    "s_y_cat = torch.cat(all_s_y)\n",
    "stats = latent_space_stats(s_y_cat)\n",
    "print(f\"\\nLatent health: var={stats['variance']:.2f}, avg_cos={stats['avg_pairwise_cosine']:.4f}, collapse={stats['collapse_detected']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Latent space visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from src.utils.data_loading import ReasoningDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model.eval()\n",
    "sample = val_data[:200]\n",
    "dataset = ReasoningDataset(sample, tokenizer, max_context_len=256, max_target_len=256)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_sx, all_sy, all_sy_hat, difficulties = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        sx = model.encode_context(batch[\"context_ids\"], batch[\"context_mask\"])\n",
    "        sy = model.encode_target(batch[\"target_ids\"], batch[\"target_mask\"])\n",
    "        sy_hat = model.predict(sx)\n",
    "        all_sx.append(sx.cpu())\n",
    "        all_sy.append(sy.cpu())\n",
    "        all_sy_hat.append(sy_hat.cpu())\n",
    "\n",
    "sx_cat = torch.cat(all_sx).numpy()\n",
    "sy_cat = torch.cat(all_sy).numpy()\n",
    "sy_hat_cat = torch.cat(all_sy_hat).numpy()\n",
    "diffs = [s.get(\"difficulty\", 0) for s in sample[:len(sx_cat)]]\n",
    "\n",
    "# PCA visualization\n",
    "pca = PCA(n_components=2)\n",
    "combined = np.vstack([sy_cat, sy_hat_cat])\n",
    "proj = pca.fit_transform(combined)\n",
    "n = len(sy_cat)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Target vs Predicted\n",
    "axes[0].scatter(proj[:n, 0], proj[:n, 1], c=\"blue\", alpha=0.5, label=\"Target s_y\", s=20)\n",
    "axes[0].scatter(proj[n:, 0], proj[n:, 1], c=\"red\", alpha=0.5, label=\"Predicted ŝ_y\", s=20)\n",
    "for i in range(min(n, 30)):\n",
    "    axes[0].plot([proj[i,0], proj[n+i,0]], [proj[i,1], proj[n+i,1]], 'gray', alpha=0.2, linewidth=0.5)\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"Target vs Predicted Latents (PCA)\")\n",
    "\n",
    "# Plot 2: By difficulty\n",
    "colors = {0: \"green\", 1: \"orange\", 2: \"red\"}\n",
    "labels = {0: \"Easy\", 1: \"Medium\", 2: \"Hard\"}\n",
    "for d in sorted(set(diffs)):\n",
    "    mask = [i for i, dd in enumerate(diffs) if dd == d]\n",
    "    axes[1].scatter(proj[mask, 0], proj[mask, 1], c=colors.get(d, \"gray\"), alpha=0.6, label=labels.get(d, f\"Diff {d}\"), s=20)\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Latent Space by Difficulty\")\n",
    "\n",
    "# Plot 3: Prediction error distribution\n",
    "errors = np.linalg.norm(sy_cat - sy_hat_cat, axis=1)\n",
    "axes[2].hist(errors, bins=30, color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[2].axvline(errors.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {errors.mean():.3f}\")\n",
    "axes[2].legend()\n",
    "axes[2].set_title(\"Prediction Error Distribution\")\n",
    "axes[2].set_xlabel(\"L2 distance (s_y, ŝ_y)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"latent_analysis.png\", dpi=150)\n",
    "plt.show()\n",
    "print(f\"Mean prediction error: {errors.mean():.4f} ± {errors.std():.4f}\")\n",
    "print(f\"Explained variance by PCA: {pca.explained_variance_ratio_.sum()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save checkpoint to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import shutil\n",
    "save_dir = \"/content/drive/MyDrive/jepa_reasoner_checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "shutil.copy(\"checkpoints/a100_full/final.pt\", f\"{save_dir}/final.pt\")\n",
    "shutil.copy(\"latent_analysis.png\", f\"{save_dir}/latent_analysis.png\")\n",
    "print(f\"Saved to {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
